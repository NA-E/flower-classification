{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# Introduction #\n\nProject on Flower Classification with Convolutional Neural Network for COMP 8610 â€“ Project 2.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Required Libraries ","metadata":{}},{"cell_type":"code","source":"import math, re, os\nimport numpy as np\nimport tensorflow as tf\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:38:15.818528Z","iopub.execute_input":"2023-04-04T20:38:15.819221Z","iopub.status.idle":"2023-04-04T20:38:55.379722Z","shell.execute_reply.started":"2023-04-04T20:38:15.819191Z","shell.execute_reply":"2023-04-04T20:38:55.378451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting Distribution Strategy for TPU\n","metadata":{}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:07:10.647355Z","iopub.execute_input":"2023-04-05T00:07:10.648254Z","iopub.status.idle":"2023-04-05T00:07:20.365384Z","shell.execute_reply.started":"2023-04-05T00:07:10.648217Z","shell.execute_reply":"2023-04-05T00:07:20.364000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Loading the Data\n\n\n","metadata":{}},{"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')\nprint(GCS_DS_PATH) ","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:03:08.040661Z","iopub.execute_input":"2023-04-05T04:03:08.041093Z","iopub.status.idle":"2023-04-05T04:03:08.048364Z","shell.execute_reply.started":"2023-04-05T04:03:08.041063Z","shell.execute_reply":"2023-04-05T04:03:08.046782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nIMAGE_SIZE = [512, 512]\nGCS_PATH = GCS_DS_PATH + '/tfrecords-jpeg-512x512'\nAUTO = tf.data.experimental.AUTOTUNE\n\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\nVALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') \n\nCLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102\n\n#processing the images into floats from 0,1 and reshaping to the size required for a TPU.\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  \n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) \n    return image\n\n#reading the labels for my images and returns a dataset with the image and label in a pair.\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  \n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label \n\n#reading the unlabeled data to use for testing.\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), \n        \"id\": tf.io.FixedLenFeature([], tf.string),  \n\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum \n\n#Reading multiple files at once to improve performance. \n#Ordering data order decreases the speed and as the data will be shuffled later on anyways. \ndef load_dataset(filenames, labeled=True, ordered=False):\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disabling order\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n    dataset = dataset.with_options(ignore_order) \n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-04-05T04:03:12.269615Z","iopub.execute_input":"2023-04-05T04:03:12.270032Z","iopub.status.idle":"2023-04-05T04:03:12.306339Z","shell.execute_reply.started":"2023-04-05T04:03:12.270002Z","shell.execute_reply":"2023-04-05T04:03:12.304833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Data Pipelines ##\n\nSplitting into train test data","metadata":{}},{"cell_type":"code","source":"\ndef data_augment(image, label):\n    #data augmentation to prevent overfitting and to find more patterns.\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_saturation(image, 0, 2)\n    return image, label   \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.repeat(10)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # get next batch while training \n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-04-05T04:03:31.272345Z","iopub.execute_input":"2023-04-05T04:03:31.273336Z","iopub.status.idle":"2023-04-05T04:03:31.288050Z","shell.execute_reply.started":"2023-04-05T04:03:31.273295Z","shell.execute_reply":"2023-04-05T04:03:31.286614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16 \n\nds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()\n\nprint(\"Training:\", ds_train)\nprint (\"Validation:\", ds_valid)\nprint(\"Test:\", ds_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:03:47.984613Z","iopub.execute_input":"2023-04-05T04:03:47.985042Z","iopub.status.idle":"2023-04-05T04:03:48.408229Z","shell.execute_reply.started":"2023-04-05T04:03:47.985013Z","shell.execute_reply":"2023-04-05T04:03:48.406655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.set_printoptions(threshold=15, linewidth=80)\n\nprint(\"Training data shapes:\")\nfor image, label in ds_train.take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Training data label examples:\", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:08:06.385963Z","iopub.execute_input":"2023-04-05T00:08:06.386746Z","iopub.status.idle":"2023-04-05T00:08:07.675623Z","shell.execute_reply.started":"2023-04-05T00:08:06.386712Z","shell.execute_reply":"2023-04-05T00:08:07.674131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Test data shapes:\")\nfor image, idnum in ds_test.take(3):\n    print(image.numpy().shape, idnum.numpy().shape)\nprint(\"Test data IDs:\", idnum.numpy().astype('U')) ","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:08:15.289502Z","iopub.execute_input":"2023-04-05T00:08:15.290721Z","iopub.status.idle":"2023-04-05T00:08:15.531034Z","shell.execute_reply.started":"2023-04-05T00:08:15.290681Z","shell.execute_reply":"2023-04-05T00:08:15.529689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration\n","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object: \n        numpy_labels = [None for _ in enumerate(numpy_images)]\n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n    \ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()\n\n\ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: \n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-04-04T23:26:41.781881Z","iopub.execute_input":"2023-04-04T23:26:41.782858Z","iopub.status.idle":"2023-04-04T23:26:41.805883Z","shell.execute_reply.started":"2023-04-04T23:26:41.782821Z","shell.execute_reply":"2023-04-04T23:26:41.804542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_iter = iter(ds_train.unbatch().batch(20))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:26:52.606299Z","iopub.execute_input":"2023-04-04T23:26:52.607563Z","iopub.status.idle":"2023-04-04T23:26:52.772985Z","shell.execute_reply.started":"2023-04-04T23:26:52.607523Z","shell.execute_reply":"2023-04-04T23:26:52.771357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The below code block can be reran to get a new batch of data.","metadata":{}},{"cell_type":"code","source":"one_batch = next(ds_iter)\ndisplay_batch_of_images(one_batch)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:26:57.250238Z","iopub.execute_input":"2023-04-04T23:26:57.250862Z","iopub.status.idle":"2023-04-04T23:27:01.415506Z","shell.execute_reply.started":"2023-04-04T23:26:57.250812Z","shell.execute_reply":"2023-04-04T23:27:01.413936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining Baseline Model","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, BatchNormalization\nfrom keras.layers import Dense, Dropout\n\nEPOCHS = 20\n\n \n# model0 = tf.keras.Sequential()\n# model0.add(Dense(1024, activation='relu', input_shape=(512,512,3)))\n# BatchNormalization(axis=1, momentum=0.06),\n# model0.add(Dropout(0.01)),\n# model0.add(Dense(2048, activation='relu'))\n# BatchNormalization(axis=1, momentum=0.06),\n# model0.add(Dropout(0.01)),\n# model0.add(Dense(2048, activation='relu'))\n# BatchNormalization(axis=1, momentum=0.06),\n# model0.add(Dropout(0.01)),\n# model0.add(Dense(1024, activation='relu'))\n# BatchNormalization(axis=1, momentum=0.06),\n# model0.add(Dropout(0.01)),\n# model0.add(Dense(len(CLASSES), activation='softmax'))\n    \n# modelZero = tf.keras.Sequential([\n#     tf.keras.layers.Dense(1024, activation = \"relu\"),\n#     tf.keras.layers.BatchNormalization(),  \n#     tf.keras.layers.Dropout(0.5),\n#     tf.keras.layers.Dense(2048, activation = \"relu\"),\n#     tf.keras.layers.BatchNormalization(),  \n#     tf.keras.layers.Dropout(0.5),\n#     tf.keras.layers.Dense(2048, activation = \"relu\"),\n#     tf.keras.layers.BatchNormalization(),  \n#     tf.keras.layers.Dropout(0.5),\n#     tf.keras.layers.Dense(1024, activation = \"relu\"),\n#     tf.keras.layers.BatchNormalization(),  \n#     tf.keras.layers.Dropout(0.5),\n#     tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n# ])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T22:29:41.766175Z","iopub.execute_input":"2023-04-04T22:29:41.767255Z","iopub.status.idle":"2023-04-04T22:29:41.930151Z","shell.execute_reply.started":"2023-04-04T22:29:41.767214Z","shell.execute_reply":"2023-04-04T22:29:41.928625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\ngu_seed=tf.keras.initializers.GlorotUniform(seed=1)\n\nEPOCHS = 20\nwith strategy.scope():\n    \"\"\"pretrained_model = tf.keras.applications.VGG16(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    pretrained_model.trainable = False\n    \n    model = tf.keras.Sequential(([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model,\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ]))\"\"\"\n    model0 = tf.keras.Sequential()\n    model0.add(Conv2D(32, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu', input_shape=(512,512,3)))\n    model0.add(MaxPool2D(pool_size=(3,3)))\n    model0.add(Dropout(0.25))\n    \n    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n    model0.add(MaxPool2D(pool_size=(3,3)))\n    model0.add(Dropout(0.25))\n    \n    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n    model0.add(MaxPool2D(pool_size=(3,3)))\n    model0.add(Dropout(0.25))\n    \n    model0.add(Flatten())\n    model0.add(Dense(len(CLASSES), activation='softmax'))\n    \n    \n    \"\"\"\n    model2 = tf.keras.Sequential()\n    model2.add(Conv2D(32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(512,512,1)))\n    model2.add(MaxPool2D(pool_size=(3,3)))\n    model2.add(Dropout(0.25))\n    \n    model2.add(Conv2D(64, kernel_size=(5,5), padding='same', activation='relu'))\n    model2.add(MaxPool2D(pool_size=(3,3)))\n    model2.add(Dropout(0.25))\n    \n    model2.add(Flatten())\n    model2.add(Dense(len(CLASSES), activation='softmax'))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-04-04T22:39:44.862907Z","iopub.execute_input":"2023-04-04T22:39:44.863792Z","iopub.status.idle":"2023-04-04T22:39:46.640004Z","shell.execute_reply.started":"2023-04-04T22:39:44.863755Z","shell.execute_reply":"2023-04-04T22:39:46.638375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model0.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nmodel0.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T22:39:53.259146Z","iopub.execute_input":"2023-04-04T22:39:53.260066Z","iopub.status.idle":"2023-04-04T22:39:53.361292Z","shell.execute_reply.started":"2023-04-04T22:39:53.260029Z","shell.execute_reply":"2023-04-04T22:39:53.360024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training epochs\nEPOCHS = 20\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nhistory = model0.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T22:40:00.658121Z","iopub.execute_input":"2023-04-04T22:40:00.659107Z","iopub.status.idle":"2023-04-04T22:55:22.341987Z","shell.execute_reply.started":"2023-04-04T22:40:00.659066Z","shell.execute_reply":"2023-04-04T22:55:22.340556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Baseline Graphs\n","metadata":{}},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T22:59:20.419437Z","iopub.execute_input":"2023-04-04T22:59:20.420460Z","iopub.status.idle":"2023-04-04T22:59:21.151919Z","shell.execute_reply.started":"2023-04-04T22:59:20.420418Z","shell.execute_reply":"2023-04-04T22:59:21.150539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Baseline Confusion matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilities = model0.predict(images_ds)\ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T / cmat.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-04-04T22:59:39.183020Z","iopub.execute_input":"2023-04-04T22:59:39.184131Z","iopub.status.idle":"2023-04-04T22:59:57.860569Z","shell.execute_reply.started":"2023-04-04T22:59:39.184094Z","shell.execute_reply":"2023-04-04T22:59:57.859130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nscore = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmat, score, precision, recall)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:00:02.644046Z","iopub.execute_input":"2023-04-04T23:00:02.645035Z","iopub.status.idle":"2023-04-04T23:00:04.879922Z","shell.execute_reply.started":"2023-04-04T23:00:02.644999Z","shell.execute_reply":"2023-04-04T23:00:04.878587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nconfusion = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\n\ntotal = np.sum(confusion)\naccuracy = np.trace(confusion) / float(total)\nspecificity = np.diag(confusion)[0] / np.sum(confusion[0])\nsensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\nppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\nnpv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n\n# Print the results\nprint(\"Accuracy:\", accuracy)\nprint(\"Specificity:\", specificity)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"PPV:\", ppv)\nprint(\"NPV:\", npv)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:00:30.354049Z","iopub.execute_input":"2023-04-04T23:00:30.355059Z","iopub.status.idle":"2023-04-04T23:00:30.366896Z","shell.execute_reply.started":"2023-04-04T23:00:30.355014Z","shell.execute_reply":"2023-04-04T23:00:30.365486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining first model - Transfer learning\n ResNet50\n\n","metadata":{}},{"cell_type":"markdown","source":"**Ignoring model due to poor accuracy**","metadata":{}},{"cell_type":"code","source":"EPOCHS = 20\nwith strategy.scope():\n    pretrained_model = tf.keras.applications.resnet50.ResNet50(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n        \n    )\n    pretrained_model.trainable = False\n    \n    model = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(1024, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(2048, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(2048, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(1024, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:27:18.053862Z","iopub.execute_input":"2023-04-04T23:27:18.054872Z","iopub.status.idle":"2023-04-04T23:27:33.893596Z","shell.execute_reply.started":"2023-04-04T23:27:18.054830Z","shell.execute_reply":"2023-04-04T23:27:33.892253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:27:40.914143Z","iopub.execute_input":"2023-04-04T23:27:40.914853Z","iopub.status.idle":"2023-04-04T23:27:41.050172Z","shell.execute_reply.started":"2023-04-04T23:27:40.914818Z","shell.execute_reply":"2023-04-04T23:27:41.048955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training #\n\n## Defining Learning Rate Schedule ##\n\nUsing a learning rate schedule that slows down to have a better chance at reaching global mimimum","metadata":{}},{"cell_type":"code","source":"def adapt_learning_rate(epoch,\n                   start_lr = 0.0005, min_lr = 0.00005, max_lr = 0.0001,\n                   rampup_epochs = 8, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(adapt_learning_rate, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [adapt_learning_rate(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-04-04T23:27:50.304808Z","iopub.execute_input":"2023-04-04T23:27:50.305958Z","iopub.status.idle":"2023-04-04T23:27:50.535255Z","shell.execute_reply.started":"2023-04-04T23:27:50.305919Z","shell.execute_reply":"2023-04-04T23:27:50.533788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fit Model ##\n\nTraining the model over 20 Epochs","metadata":{}},{"cell_type":"code","source":"# Define training epochs\nEPOCHS = 20\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:27:58.524876Z","iopub.execute_input":"2023-04-04T23:27:58.525894Z","iopub.status.idle":"2023-04-04T23:30:10.476113Z","shell.execute_reply.started":"2023-04-04T23:27:58.525858Z","shell.execute_reply":"2023-04-04T23:30:10.474412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T21:06:55.915836Z","iopub.execute_input":"2023-04-04T21:06:55.916283Z","iopub.status.idle":"2023-04-04T21:06:56.599388Z","shell.execute_reply.started":"2023-04-04T21:06:55.916251Z","shell.execute_reply":"2023-04-04T21:06:56.598119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation Model 1\n","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn","metadata":{"execution":{"iopub.status.busy":"2023-04-04T21:14:15.968373Z","iopub.execute_input":"2023-04-04T21:14:15.968805Z","iopub.status.idle":"2023-04-04T21:14:25.154009Z","shell.execute_reply.started":"2023-04-04T21:14:15.968772Z","shell.execute_reply":"2023-04-04T21:14:25.152418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import confusion_matrix\n\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilities = model.predict(images_ds)\ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T / cmat.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:00:57.699833Z","iopub.execute_input":"2023-04-04T23:00:57.700212Z","iopub.status.idle":"2023-04-04T23:01:08.699649Z","shell.execute_reply.started":"2023-04-04T23:00:57.700183Z","shell.execute_reply":"2023-04-04T23:01:08.698254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2023-04-04T21:24:41.549154Z","iopub.execute_input":"2023-04-04T21:24:41.549821Z","iopub.status.idle":"2023-04-04T21:24:41.558601Z","shell.execute_reply.started":"2023-04-04T21:24:41.549756Z","shell.execute_reply":"2023-04-04T21:24:41.557101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nconfusion = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\n\ntotal = np.sum(confusion)\naccuracy = np.trace(confusion) / float(total)\nspecificity = np.diag(confusion)[0] / np.sum(confusion[0])\nsensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\nppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\nnpv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n\n# Print the results\nprint(\"Accuracy:\", accuracy)\nprint(\"Specificity:\", specificity)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"PPV:\", ppv)\nprint(\"NPV:\", npv)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:01:16.980090Z","iopub.execute_input":"2023-04-04T23:01:16.980556Z","iopub.status.idle":"2023-04-04T23:01:16.993679Z","shell.execute_reply.started":"2023-04-04T23:01:16.980520Z","shell.execute_reply":"2023-04-04T23:01:16.992390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nscore = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmat, score, precision, recall)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T21:18:42.012985Z","iopub.execute_input":"2023-04-04T21:18:42.013918Z","iopub.status.idle":"2023-04-04T21:18:44.304655Z","shell.execute_reply.started":"2023-04-04T21:18:42.013879Z","shell.execute_reply":"2023-04-04T21:18:44.303386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining second model - Transfer Learning\nResNet50 model ","metadata":{}},{"cell_type":"markdown","source":"**Ignoring model due to poor accuracy**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\ngu_seed=tf.keras.initializers.GlorotUniform(seed=1)\n\nEPOCHS = 20\nwith strategy.scope():\n    \"\"\"pretrained_model = tf.keras.applications.VGG16(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    pretrained_model.trainable = False\n    \n    model = tf.keras.Sequential(([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model,\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ]))\"\"\"\n    model0 = tf.keras.Sequential()\n    model0.add(Conv2D(32, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu', input_shape=(512,512,3)))\n    model0.add(MaxPool2D(pool_size=(3,3)))\n    model0.add(Dropout(0.25))\n    \n    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n    model0.add(MaxPool2D(pool_size=(3,3)))\n    model0.add(Dropout(0.25))\n    \n    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n    model0.add(MaxPool2D(pool_size=(3,3)))\n    model0.add(Dropout(0.25))\n    \n    model0.add(Flatten())\n    model0.add(Dense(len(CLASSES), activation='softmax'))\n    \n    \n    \"\"\"\n    model2 = tf.keras.Sequential()\n    model2.add(Conv2D(32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(512,512,1)))\n    model2.add(MaxPool2D(pool_size=(3,3)))\n    model2.add(Dropout(0.25))\n    \n    model2.add(Conv2D(64, kernel_size=(5,5), padding='same', activation='relu'))\n    model2.add(MaxPool2D(pool_size=(3,3)))\n    model2.add(Dropout(0.25))\n    \n    model2.add(Flatten())\n    model2.add(Dense(len(CLASSES), activation='softmax'))\"\"\"\n\n\nEPOCHS = 20\nwith strategy.scope():\n    pretrained_model = tf.keras.applications.resnet50.ResNet50(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n        \n    )\n    pretrained_model.trainable = True\n    \n    modelTwo = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5), \n        \n    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n    model0.add(MaxPool2D(pool_size=(3,3)))\n    model0.add(Dropout(0.25))\n    \n    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n    model0.add(MaxPool2D(pool_size=(3,3)))\n    model0.add(Dropout(0.25))\n    \n    model0.add(Flatten())        \n        \n        \n        \n        \n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])\n    \n    \n    model = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(1024, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(2048, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(2048, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(1024, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:30:39.358653Z","iopub.execute_input":"2023-04-04T23:30:39.359620Z","iopub.status.idle":"2023-04-04T23:30:52.798044Z","shell.execute_reply.started":"2023-04-04T23:30:39.359584Z","shell.execute_reply":"2023-04-04T23:30:52.796807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelTwo.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nmodelTwo.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:31:40.307992Z","iopub.execute_input":"2023-04-04T23:31:40.309250Z","iopub.status.idle":"2023-04-04T23:31:40.433025Z","shell.execute_reply.started":"2023-04-04T23:31:40.309209Z","shell.execute_reply":"2023-04-04T23:31:40.431788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adapt_learning_rate(epoch,\n                   start_lr = 0.0005, min_lr = 0.00005, max_lr = 0.0001,\n                   rampup_epochs = 8, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(adapt_learning_rate, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [adapt_learning_rate(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:31:49.773115Z","iopub.execute_input":"2023-04-04T23:31:49.774154Z","iopub.status.idle":"2023-04-04T23:31:49.979505Z","shell.execute_reply.started":"2023-04-04T23:31:49.774120Z","shell.execute_reply":"2023-04-04T23:31:49.978246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training epochs\nEPOCHS = 20\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nhistory = modelTwo.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:31:59.221211Z","iopub.execute_input":"2023-04-04T23:31:59.222189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One interesting thing to notice is that even though the training accuracy increases significantly from the start, the model is rather slow to adapt to the patterns and learn to generalise to the validation data. This could be due to it taking much longer to change the weights of the ResNet50 model as the model itself should have set weights already.","metadata":{}},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T16:29:00.267918Z","iopub.execute_input":"2023-02-14T16:29:00.268199Z","iopub.status.idle":"2023-02-14T16:29:00.783343Z","shell.execute_reply.started":"2023-02-14T16:29:00.268175Z","shell.execute_reply":"2023-02-14T16:29:00.782497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilities = modelTwo.predict(images_ds)\ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T / cmat.sum(axis=1)).T # normalize","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nscore = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmat, score, precision, recall)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nconfusion = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\n\ntotal = np.sum(confusion)\naccuracy = np.trace(confusion) / float(total)\nspecificity = np.diag(confusion)[0] / np.sum(confusion[0])\nsensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\nppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\nnpv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n\n# Print the results\nprint(\"Accuracy:\", accuracy)\nprint(\"Specificity:\", specificity)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"PPV:\", ppv)\nprint(\"NPV:\", npv)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graphs above with a heavy fluctuation of model validation loss at the start indicates that my initial learning rate may be too high. However as both curves eventually start to move to each other, it is concluded that the network's traning graph is likely to have one big global minima (second image) rather than many local minima (first image). This means that the learning rate shouldn't have too much of an effect on the network and the network's performace is near maximised at 91% accuracy.\n<div>\n     <img src=\"attachment:764259da-fc7d-4c15-93fd-4c9b1cae20d0.jpg\" width=\"300\"/>\n</div>","metadata":{},"attachments":{"764259da-fc7d-4c15-93fd-4c9b1cae20d0.jpg":{"image/jpeg":"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"}}},{"cell_type":"markdown","source":"# Defining Third model - Transfer Learning\nXception model. ","metadata":{}},{"cell_type":"markdown","source":"**Ignoring model due to poor accuracy**","metadata":{}},{"cell_type":"code","source":"EPOCHS = 20\nwith strategy.scope():\n    pretrained_model = tf.keras.applications.Xception(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n        \n    )\n    pretrained_model.trainable = False\n    \n    modelThree = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dense(1024, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.Dense(2048, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(4096, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(2048, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(), \n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(1024, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dense(512, activation = \"relu\"),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:08:39.503067Z","iopub.execute_input":"2023-04-05T00:08:39.503504Z","iopub.status.idle":"2023-04-05T00:08:52.421758Z","shell.execute_reply.started":"2023-04-05T00:08:39.503462Z","shell.execute_reply":"2023-04-05T00:08:52.420481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelThree.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nmodelThree.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:08:59.682219Z","iopub.execute_input":"2023-04-05T00:08:59.683437Z","iopub.status.idle":"2023-04-05T00:08:59.864677Z","shell.execute_reply.started":"2023-04-05T00:08:59.683380Z","shell.execute_reply":"2023-04-05T00:08:59.863477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adapt_learning_rate(epoch,\n                   start_lr = 0.0005, min_lr = 0.00005, max_lr = 0.0001,\n                   rampup_epochs = 6, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(adapt_learning_rate, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [adapt_learning_rate(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:09:11.147002Z","iopub.execute_input":"2023-04-05T00:09:11.147373Z","iopub.status.idle":"2023-04-05T00:09:11.359656Z","shell.execute_reply.started":"2023-04-05T00:09:11.147346Z","shell.execute_reply":"2023-04-05T00:09:11.358579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training epochs\nEPOCHS = 20\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nhistory = modelThree.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:09:18.829096Z","iopub.execute_input":"2023-04-05T00:09:18.830027Z","iopub.status.idle":"2023-04-05T00:25:40.393087Z","shell.execute_reply.started":"2023-04-05T00:09:18.829990Z","shell.execute_reply":"2023-04-05T00:25:40.391461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:27:20.922185Z","iopub.execute_input":"2023-04-05T00:27:20.922622Z","iopub.status.idle":"2023-04-05T00:27:21.654558Z","shell.execute_reply.started":"2023-04-05T00:27:20.922587Z","shell.execute_reply":"2023-04-05T00:27:21.653147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import confusion_matrix\n\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilities = modelThree.predict(images_ds)\ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T / cmat.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:27:30.066428Z","iopub.execute_input":"2023-04-05T00:27:30.066803Z","iopub.status.idle":"2023-04-05T00:27:53.277974Z","shell.execute_reply.started":"2023-04-05T00:27:30.066773Z","shell.execute_reply":"2023-04-05T00:27:53.276604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nscore = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmat, score, precision, recall)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:27:57.712380Z","iopub.execute_input":"2023-04-05T00:27:57.712704Z","iopub.status.idle":"2023-04-05T00:27:59.844413Z","shell.execute_reply.started":"2023-04-05T00:27:57.712678Z","shell.execute_reply":"2023-04-05T00:27:59.843108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nconfusion = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\n\ntotal = np.sum(confusion)\naccuracy = np.trace(confusion) / float(total)\nspecificity = np.diag(confusion)[0] / np.sum(confusion[0])\nsensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\nppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\nnpv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n\n# Print the results\nprint(\"Accuracy:\", accuracy)\nprint(\"Specificity:\", specificity)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"PPV:\", ppv)\nprint(\"NPV:\", npv)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T23:23:54.161201Z","iopub.execute_input":"2023-04-04T23:23:54.162217Z","iopub.status.idle":"2023-04-04T23:23:54.174009Z","shell.execute_reply.started":"2023-04-04T23:23:54.162181Z","shell.execute_reply":"2023-04-04T23:23:54.172659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate Predictions #\n","metadata":{}},{"cell_type":"code","source":"EPOCHS = 20\nwith strategy.scope():\n    pretrained_model = tf.keras.applications.resnet50.ResNet50(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n        \n    )\n    pretrained_model.trainable = True\n    \n    model = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.BatchNormalization(),  \n        tf.keras.layers.Dropout(0.5), \n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-02-18T11:57:46.727918Z","iopub.execute_input":"2023-02-18T11:57:46.728524Z","iopub.status.idle":"2023-02-18T11:57:58.586581Z","shell.execute_reply.started":"2023-02-18T11:57:46.728474Z","shell.execute_reply":"2023-02-18T11:57:58.585248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-18T11:57:58.588228Z","iopub.execute_input":"2023-02-18T11:57:58.588467Z","iopub.status.idle":"2023-02-18T11:57:58.650259Z","shell.execute_reply.started":"2023-02-18T11:57:58.588437Z","shell.execute_reply":"2023-02-18T11:57:58.648818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adapt_learning_rate(epoch,\n                   start_lr = 0.0005, min_lr = 0.00005, max_lr = 0.0001,\n                   rampup_epochs = 8, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(adapt_learning_rate, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [adapt_learning_rate(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-02-18T11:57:58.651982Z","iopub.execute_input":"2023-02-18T11:57:58.652249Z","iopub.status.idle":"2023-02-18T11:57:58.826885Z","shell.execute_reply.started":"2023-02-18T11:57:58.652216Z","shell.execute_reply":"2023-02-18T11:57:58.825618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training epochs\nEPOCHS = 20\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nhistory = modelThree.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T11:58:07.133443Z","iopub.execute_input":"2023-02-18T11:58:07.133734Z","iopub.status.idle":"2023-02-18T12:10:49.642463Z","shell.execute_reply.started":"2023-02-18T11:58:07.133704Z","shell.execute_reply":"2023-02-18T12:10:49.640758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Trainng and Validation Loss and Accuracy Curves ##","metadata":{}},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T12:24:53.04269Z","iopub.execute_input":"2023-02-18T12:24:53.043003Z","iopub.status.idle":"2023-02-18T12:24:53.482714Z","shell.execute_reply.started":"2023-02-18T12:24:53.042975Z","shell.execute_reply":"2023-02-18T12:24:53.48151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#move up??\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\ndef display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(15,15))\n    ax = plt.gca()\n    ax.matshow(cmat, cmap='Reds')\n    ax.set_xticks(range(len(CLASSES)))\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n    ax.set_yticks(range(len(CLASSES)))\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall)\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n    plt.show()\n    \ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","metadata":{"_kg_hide-input":true,"scrolled":true,"execution":{"iopub.status.busy":"2023-04-04T21:18:30.829589Z","iopub.execute_input":"2023-04-04T21:18:30.830619Z","iopub.status.idle":"2023-04-04T21:18:30.846958Z","shell.execute_reply.started":"2023-04-04T21:18:30.830576Z","shell.execute_reply":"2023-04-04T21:18:30.845694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix ##\n\n","metadata":{}},{"cell_type":"code","source":"cmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilities = model.predict(images_ds)\ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T / cmat.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-02-18T12:25:46.77152Z","iopub.execute_input":"2023-02-18T12:25:46.772044Z","iopub.status.idle":"2023-02-18T12:25:52.123943Z","shell.execute_reply.started":"2023-02-18T12:25:46.772011Z","shell.execute_reply":"2023-02-18T12:25:52.123064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmat, score, precision, recall)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T12:25:55.053327Z","iopub.execute_input":"2023-02-18T12:25:55.053678Z","iopub.status.idle":"2023-02-18T12:25:58.733166Z","shell.execute_reply.started":"2023-02-18T12:25:55.053615Z","shell.execute_reply":"2023-02-18T12:25:58.732248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visual Validation ##\n","metadata":{}},{"cell_type":"code","source":"dataset = get_validation_dataset()\ndataset = dataset.unbatch().batch(20)\nbatch = iter(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T12:26:04.254271Z","iopub.execute_input":"2023-02-18T12:26:04.255256Z","iopub.status.idle":"2023-02-18T12:26:04.299221Z","shell.execute_reply.started":"2023-02-18T12:26:04.255204Z","shell.execute_reply":"2023-02-18T12:26:04.298218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(batch)\nprobabilities = model.predict(images)\npredictions = np.argmax(probabilities, axis=-1)\ndisplay_batch_of_images((images, labels), predictions)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T12:26:06.367347Z","iopub.execute_input":"2023-02-18T12:26:06.367818Z","iopub.status.idle":"2023-02-18T12:26:18.878202Z","shell.execute_reply.started":"2023-02-18T12:26:06.367784Z","shell.execute_reply":"2023-02-18T12:26:18.877498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# New Code","metadata":{}},{"cell_type":"markdown","source":"# Transfer Learning New Model 1 - ResNet50","metadata":{}},{"cell_type":"code","source":"EPOCHS = 50\nfrom tensorflow.keras.models import Model\n\n\nwith strategy.scope():\n    pretrained_model = tf.keras.applications.resnet50.ResNet50(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3],\n        pooling='avg',\n    )\n    pretrained_model.trainable = True\n    \n    x = pretrained_model.output\n    predictions = tf.keras.layers.Dense(len(CLASSES), activation='softmax')(x)\n    modelOne = tf.keras.models.Model(inputs=pretrained_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:35:09.916566Z","iopub.execute_input":"2023-04-05T00:35:09.917040Z","iopub.status.idle":"2023-04-05T00:35:21.972107Z","shell.execute_reply.started":"2023-04-05T00:35:09.917005Z","shell.execute_reply":"2023-04-05T00:35:21.970761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelOne.compile(\n    optimizer='nadam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nmodelOne.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:35:26.079117Z","iopub.execute_input":"2023-04-05T00:35:26.080093Z","iopub.status.idle":"2023-04-05T00:35:26.540933Z","shell.execute_reply.started":"2023-04-05T00:35:26.080055Z","shell.execute_reply":"2023-04-05T00:35:26.539524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning Rate Schedule for Fine Tuning #\ndef exponential_lr(epoch,\n                   start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005,\n                   rampup_epochs = 5, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        # constant max_lr during sustain_epochs\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        # exponential decay towards min_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:36:53.365077Z","iopub.execute_input":"2023-04-05T00:36:53.365438Z","iopub.status.idle":"2023-04-05T00:36:53.585338Z","shell.execute_reply.started":"2023-04-05T00:36:53.365410Z","shell.execute_reply":"2023-04-05T00:36:53.584132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training epochs\nEPOCHS = 20\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nhistory = modelOne.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T00:37:23.568902Z","iopub.execute_input":"2023-04-05T00:37:23.569887Z","iopub.status.idle":"2023-04-05T01:04:21.235688Z","shell.execute_reply.started":"2023-04-05T00:37:23.569848Z","shell.execute_reply":"2023-04-05T01:04:21.234190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T01:05:43.122617Z","iopub.execute_input":"2023-04-05T01:05:43.123013Z","iopub.status.idle":"2023-04-05T01:05:43.807862Z","shell.execute_reply.started":"2023-04-05T01:05:43.122982Z","shell.execute_reply":"2023-04-05T01:05:43.806579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilitiesOne = modelOne.predict(images_ds)\ncm_predictionsOne = np.argmax(cm_probabilitiesOne, axis=-1)\n\nlabels = range(len(CLASSES))\ncmatOne = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsOne,\n    labels=labels,\n)\ncmatOne = (cmatOne.T / cmatOne.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-04-05T01:05:53.620800Z","iopub.execute_input":"2023-04-05T01:05:53.621922Z","iopub.status.idle":"2023-04-05T01:06:17.537705Z","shell.execute_reply.started":"2023-04-05T01:05:53.621887Z","shell.execute_reply":"2023-04-05T01:06:17.536146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nscoreOne = f1_score(\n    cm_correct_labels,\n    cm_predictionsOne,\n    labels=labels,\n    average='macro',\n)\nprecisionOne = precision_score(\n    cm_correct_labels,\n    cm_predictionsOne,\n    labels=labels,\n    average='macro',\n)\nrecallOne = recall_score(\n    cm_correct_labels,\n    cm_predictionsOne,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmatOne, scoreOne, precisionOne, recallOne)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T01:07:24.229772Z","iopub.execute_input":"2023-04-05T01:07:24.230785Z","iopub.status.idle":"2023-04-05T01:07:26.503764Z","shell.execute_reply.started":"2023-04-05T01:07:24.230746Z","shell.execute_reply":"2023-04-05T01:07:26.502422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nconfusion = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsOne,\n    labels=labels,\n)\n\ntotal = np.sum(confusion)\naccuracy = np.trace(confusion) / float(total)\nspecificity = np.diag(confusion)[0] / np.sum(confusion[0])\nsensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\nppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\nnpv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n\n# Print the results\nprint(\"Model One - Transfer Learning - ResNet50\")\nprint(\"Accuracy:\", accuracy)\nprint(\"Specificity:\", specificity)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"PPV:\", ppv)\nprint(\"NPV:\", npv)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T01:07:41.131007Z","iopub.execute_input":"2023-04-05T01:07:41.131648Z","iopub.status.idle":"2023-04-05T01:07:41.144000Z","shell.execute_reply.started":"2023-04-05T01:07:41.131596Z","shell.execute_reply":"2023-04-05T01:07:41.142481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning New Model 2 -  DenseNet201 ","metadata":{}},{"cell_type":"code","source":"EPOCHS = 50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import DenseNet201\n\n\nwith strategy.scope():\n    pretrained_model = tf.keras.applications.DenseNet201(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3],\n        pooling='avg',\n    )\n    pretrained_model.trainable = True\n    \n    x = pretrained_model.output\n    predictions = tf.keras.layers.Dense(len(CLASSES), activation='softmax')(x)\n    modelTwoNew = tf.keras.models.Model(inputs=pretrained_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T01:11:04.141704Z","iopub.execute_input":"2023-04-05T01:11:04.142113Z","iopub.status.idle":"2023-04-05T01:11:38.662921Z","shell.execute_reply.started":"2023-04-05T01:11:04.142080Z","shell.execute_reply":"2023-04-05T01:11:38.661356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning Rate Schedule for Fine Tuning #\ndef exponential_lr(epoch,\n                   start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005,\n                   rampup_epochs = 5, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        # constant max_lr during sustain_epochs\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        # exponential decay towards min_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-05T01:12:10.826845Z","iopub.execute_input":"2023-04-05T01:12:10.827224Z","iopub.status.idle":"2023-04-05T01:12:11.044599Z","shell.execute_reply.started":"2023-04-05T01:12:10.827196Z","shell.execute_reply":"2023-04-05T01:12:11.043194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelTwoNew.compile(\n    optimizer='nadam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nmodelTwoNew.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-05T01:11:52.965619Z","iopub.execute_input":"2023-04-05T01:11:52.966004Z","iopub.status.idle":"2023-04-05T01:11:54.531908Z","shell.execute_reply.started":"2023-04-05T01:11:52.965975Z","shell.execute_reply":"2023-04-05T01:11:54.530433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training epochs\nEPOCHS = 25\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nhistory = modelTwoNew.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T01:13:12.387366Z","iopub.execute_input":"2023-04-05T01:13:12.387899Z","iopub.status.idle":"2023-04-05T02:32:50.435378Z","shell.execute_reply.started":"2023-04-05T01:13:12.387863Z","shell.execute_reply":"2023-04-05T02:32:50.433956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:33:06.960561Z","iopub.execute_input":"2023-04-05T02:33:06.960995Z","iopub.status.idle":"2023-04-05T02:33:07.598854Z","shell.execute_reply.started":"2023-04-05T02:33:06.960962Z","shell.execute_reply":"2023-04-05T02:33:07.597580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilitiesTwo = modelTwoNew.predict(images_ds)\ncm_predictionsTwo = np.argmax(cm_probabilitiesTwo, axis=-1)\n\nlabels = range(len(CLASSES))\ncmatTwo = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsTwo,\n    labels=labels,\n)\ncmatTwo = (cmatTwo.T / cmatTwo.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:33:21.459075Z","iopub.execute_input":"2023-04-05T02:33:21.459454Z","iopub.status.idle":"2023-04-05T02:34:22.776698Z","shell.execute_reply.started":"2023-04-05T02:33:21.459426Z","shell.execute_reply":"2023-04-05T02:34:22.775075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nscoreTwo = f1_score(\n    cm_correct_labels,\n    cm_predictionsTwo,\n    labels=labels,\n    average='macro',\n)\nprecisionTwo = precision_score(\n    cm_correct_labels,\n    cm_predictionsTwo,\n    labels=labels,\n    average='macro',\n)\nrecallTwo = recall_score(\n    cm_correct_labels,\n    cm_predictionsTwo,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmatTwo, scoreTwo, precisionTwo, recallTwo)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:34:32.645343Z","iopub.execute_input":"2023-04-05T02:34:32.646244Z","iopub.status.idle":"2023-04-05T02:34:34.850137Z","shell.execute_reply.started":"2023-04-05T02:34:32.646202Z","shell.execute_reply":"2023-04-05T02:34:34.848632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nconfusion = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsTwo,\n    labels=labels,\n)\n\ntotal = np.sum(confusion)\naccuracy = np.trace(confusion) / float(total)\nspecificity = np.diag(confusion)[0] / np.sum(confusion[0])\nsensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\nppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\nnpv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n\n# Print the results\nprint(\"Model Two - Transfer Learning - DenseNet201\")\nprint(\"Accuracy:\", accuracy)\nprint(\"Specificity:\", specificity)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"PPV:\", ppv)\nprint(\"NPV:\", npv)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:34:47.597491Z","iopub.execute_input":"2023-04-05T02:34:47.598392Z","iopub.status.idle":"2023-04-05T02:34:47.610455Z","shell.execute_reply.started":"2023-04-05T02:34:47.598353Z","shell.execute_reply":"2023-04-05T02:34:47.609085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Transfer Learning New Model 3 -  Xception","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    pretrained_model_xception_seven = tf.keras.applications.Xception(input_shape=[*IMAGE_SIZE, 3],\n                                               include_top=False,\n                                               weights='imagenet')\n    \n    model_xception_seven = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model_xception_seven,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:07:11.125800Z","iopub.execute_input":"2023-04-05T04:07:11.127041Z","iopub.status.idle":"2023-04-05T04:07:21.203164Z","shell.execute_reply.started":"2023-04-05T04:07:11.127003Z","shell.execute_reply":"2023-04-05T04:07:21.201494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xception_seven.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:07:41.682008Z","iopub.execute_input":"2023-04-05T04:07:41.683373Z","iopub.status.idle":"2023-04-05T04:07:41.721626Z","shell.execute_reply.started":"2023-04-05T04:07:41.683290Z","shell.execute_reply":"2023-04-05T04:07:41.720072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    \n    model_xception_seven.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='nadam',\n                  metrics=['sparse_categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:07:49.087300Z","iopub.execute_input":"2023-04-05T04:07:49.088244Z","iopub.status.idle":"2023-04-05T04:07:49.176790Z","shell.execute_reply.started":"2023-04-05T04:07:49.088205Z","shell.execute_reply":"2023-04-05T04:07:49.175228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning Rate Schedule for Fine Tuning #\ndef exponential_lr(epoch,\n                   start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005,\n                   rampup_epochs = 5, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        # constant max_lr during sustain_epochs\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        # exponential decay towards min_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    \n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:07:54.305921Z","iopub.execute_input":"2023-04-05T04:07:54.306928Z","iopub.status.idle":"2023-04-05T04:07:54.546959Z","shell.execute_reply.started":"2023-04-05T04:07:54.306882Z","shell.execute_reply":"2023-04-05T04:07:54.545571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEPS_PER_EPOCH = 20\n\nhistory = model_xception_seven.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback, tf.keras.callbacks.ModelCheckpoint(filepath='Xception.h5', monitor='val_loss',\n                                            save_best_only=True)],\n    workers=3\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:08:04.154169Z","iopub.execute_input":"2023-04-05T04:08:04.154959Z","iopub.status.idle":"2023-04-05T04:13:45.504002Z","shell.execute_reply.started":"2023-04-05T04:08:04.154924Z","shell.execute_reply":"2023-04-05T04:13:45.502275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:13:53.077260Z","iopub.execute_input":"2023-04-05T04:13:53.078433Z","iopub.status.idle":"2023-04-05T04:13:53.756118Z","shell.execute_reply.started":"2023-04-05T04:13:53.078372Z","shell.execute_reply":"2023-04-05T04:13:53.754868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilitiesSeven = model_xception_seven.predict(images_ds)\ncm_predictionsSeven = np.argmax(cm_probabilitiesSeven, axis=-1)\n\nlabels = range(len(CLASSES))\ncmatSeven = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsSeven,\n    labels=labels,\n)\ncmatSeven = (cmatSeven.T / cmatSeven.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:14:17.267762Z","iopub.execute_input":"2023-04-05T04:14:17.268195Z","iopub.status.idle":"2023-04-05T04:14:38.253710Z","shell.execute_reply.started":"2023-04-05T04:14:17.268163Z","shell.execute_reply":"2023-04-05T04:14:38.252084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nscoreSeven = f1_score(\n    cm_correct_labels,\n    cm_predictionsSeven,\n    labels=labels,\n    average='macro',\n)\nprecisionSeven = precision_score(\n    cm_correct_labels,\n    cm_predictionsSeven,\n    labels=labels,\n    average='macro',\n)\nrecallSeven = recall_score(\n    cm_correct_labels,\n    cm_predictionsSeven,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmatSeven, scoreSeven, precisionSeven, recallSeven)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:14:41.055478Z","iopub.execute_input":"2023-04-05T04:14:41.056520Z","iopub.status.idle":"2023-04-05T04:14:43.221624Z","shell.execute_reply.started":"2023-04-05T04:14:41.056484Z","shell.execute_reply":"2023-04-05T04:14:43.220315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nconfusion = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsSeven,\n    labels=labels,\n)\n\ntotal = np.sum(confusion)\naccuracy = np.trace(confusion) / float(total)\nspecificity = np.diag(confusion)[0] / np.sum(confusion[0])\nsensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\nppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\nnpv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n\n# Print the results\nprint(\"Model Three - Transfer Learning - Xception\")\nprint(\"Accuracy:\", accuracy)\nprint(\"Specificity:\", specificity)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"PPV:\", ppv)\nprint(\"NPV:\", npv)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:14:55.932737Z","iopub.execute_input":"2023-04-05T04:14:55.933896Z","iopub.status.idle":"2023-04-05T04:14:55.945787Z","shell.execute_reply.started":"2023-04-05T04:14:55.933852Z","shell.execute_reply":"2023-04-05T04:14:55.944443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"# Data Augmentation Model 1","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\nSIZE = 512\n\nGCS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')\nGCS_PATH_EXT = KaggleDatasets().get_gcs_path('tf-flower-photo-tfrec')\nIMAGE_PATH = GCS_PATH + '/tfrecords-jpeg-{size}x{size}'.format(size=SIZE)\n\nIMAGENET_FILES = tf.io.gfile.glob(GCS_PATH_EXT + '/imagenet_no_test/tfrecords-jpeg-{size}x{size}/*.tfrec'.format(size=SIZE))\nINATURELIST_FILES = tf.io.gfile.glob(GCS_PATH_EXT + '/inaturalist_no_test/tfrecords-jpeg-{size}x{size}/*.tfrec'.format(size=SIZE))\nOPENIMAGE_FILES = tf.io.gfile.glob(GCS_PATH_EXT + '/openimage_no_test/tfrecords-jpeg-{size}x{size}/*.tfrec'.format(size=SIZE))\nOXFORD_FILES = tf.io.gfile.glob(GCS_PATH_EXT + '/oxford_102_no_test/tfrecords-jpeg-{size}x{size}/*.tfrec'.format(size=SIZE))\nTENSORFLOW_FILES = tf.io.gfile.glob(GCS_PATH_EXT + '/tf_flowers_no_test/tfrecords-jpeg-{size}x{size}/*.tfrec'.format(size=SIZE))\n\nTRAINING_FILENAMES = tf.io.gfile.glob(IMAGE_PATH + '/train/*.tfrec') + IMAGENET_FILES + INATURELIST_FILES + OPENIMAGE_FILES + OXFORD_FILES + TENSORFLOW_FILES\n\nVALIDATION_FILENAMES = tf.io.gfile.glob(IMAGE_PATH + '/val/*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(IMAGE_PATH + '/test/*.tfrec') \n\nIMAGE_SIZE = [SIZE, SIZE]\n\nBATCH_SIZE = 128\nEPOCHS = 35","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:25:46.429648Z","iopub.execute_input":"2023-04-05T04:25:46.430421Z","iopub.status.idle":"2023-04-05T04:25:46.450588Z","shell.execute_reply.started":"2023-04-05T04:25:46.430374Z","shell.execute_reply":"2023-04-05T04:25:46.449179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose'] ","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:25:55.429186Z","iopub.execute_input":"2023-04-05T04:25:55.430038Z","iopub.status.idle":"2023-04-05T04:25:55.441601Z","shell.execute_reply.started":"2023-04-05T04:25:55.430002Z","shell.execute_reply":"2023-04-05T04:25:55.440231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow-addons\n","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:47:56.770854Z","iopub.execute_input":"2023-04-05T02:47:56.771740Z","iopub.status.idle":"2023-04-05T02:48:06.854382Z","shell.execute_reply.started":"2023-04-05T02:47:56.771704Z","shell.execute_reply":"2023-04-05T02:48:06.852461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"class\": tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"id\": tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n    dataset = dataset.with_options(ignore_order)\n    \n    if labeled:\n        dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls=AUTOTUNE)\n    else:\n        dataset = dataset.map(read_unlabeled_tfrecord, num_parallel_calls=AUTOTUNE)\n    \n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:26:07.582237Z","iopub.execute_input":"2023-04-05T04:26:07.582994Z","iopub.status.idle":"2023-04-05T04:26:07.596930Z","shell.execute_reply.started":"2023-04-05T04:26:07.582960Z","shell.execute_reply":"2023-04-05T04:26:07.595534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_cut_out(image, label):\n    image = tf.expand_dims(image, axis=0)\n    return tf.squeeze(tfa.image.random_cutout(image, (192, 192), constant_values = 1), axis=0), label\n\ndef data_augment(image, label):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    image = tf.image.resize(image, [SIZE+30, SIZE+30], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    image = tf.image.random_crop(image, size=[SIZE, SIZE, 3])\n    \n    if p_rotate > .8:\n        image = tf.image.rot90(image, k=3) \n    elif p_rotate > .6:\n        image = tf.image.rot90(image, k=2) \n    elif p_rotate > .4:\n        image = tf.image.rot90(image, k=1)\n        \n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    return image, label  \n\ndef data_augment_method_three(image, label):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    image = tf.image.resize(image, [SIZE+30, SIZE+30], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    image = tf.image.random_crop(image, size=[SIZE, SIZE, 3])\n    \n    if p_rotate > .8:\n        image = tf.image.rot90(image, k=3) \n    elif p_rotate > .6:\n        image = tf.image.rot90(image, k=2) \n    elif p_rotate > .4:\n        image = tf.image.rot90(image, k=1)\n    \n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    return image, label  \n\ndef data_augment_method_two(x,y):\n    x = tf.image.random_flip_left_right(x)\n    x = tf.image.random_flip_up_down(x)\n    return x,y\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.map(random_cut_out, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n\ndef get_training_dataset_aug_two():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment_method_two, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.map(random_cut_out, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n\ndef get_training_dataset_aug_three():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment_method_three, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.map(random_cut_out, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec\n    # files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:26:15.926621Z","iopub.execute_input":"2023-04-05T04:26:15.927761Z","iopub.status.idle":"2023-04-05T04:26:15.958014Z","shell.execute_reply.started":"2023-04-05T04:26:15.927726Z","shell.execute_reply":"2023-04-05T04:26:15.956634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()\n\nprint(\"Training:\", ds_train)\nprint (\"Validation:\", ds_valid)\nprint(\"Test:\", ds_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:48:30.499496Z","iopub.execute_input":"2023-04-05T02:48:30.500650Z","iopub.status.idle":"2023-04-05T02:48:32.059343Z","shell.execute_reply.started":"2023-04-05T02:48:30.500613Z","shell.execute_reply":"2023-04-05T02:48:32.057815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation Model 2","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\n\n\n\n\nwith strategy.scope():\n    pretrained_model = tf.keras.applications.resnet50.ResNet50(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3],\n        pooling='avg',\n    )\n    pretrained_model.trainable = True\n    \n    x = pretrained_model.output\n    predictions = tf.keras.layers.Dense(len(CLASSES), activation='softmax')(x)\n    modelThreeNew = tf.keras.models.Model(inputs=pretrained_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:48:46.065045Z","iopub.execute_input":"2023-04-05T02:48:46.066122Z","iopub.status.idle":"2023-04-05T02:48:57.761307Z","shell.execute_reply.started":"2023-04-05T02:48:46.066085Z","shell.execute_reply":"2023-04-05T02:48:57.759929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelThreeNew.compile(\nÂ Â Â  optimizer='nadam',\nÂ Â Â  loss = 'sparse_categorical_crossentropy',\nÂ Â Â  metrics=['sparse_categorical_accuracy'],\n)\n\nÂ \n\nmodelThreeNew.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" USE THIS","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    pretrained_model_xception = tf.keras.applications.Xception(input_shape=[*IMAGE_SIZE, 3],\n                                               include_top=False,\n                                               weights='imagenet')\n    \n    model_xception = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model_xception,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:49:52.941440Z","iopub.execute_input":"2023-04-05T02:49:52.942792Z","iopub.status.idle":"2023-04-05T02:50:03.568622Z","shell.execute_reply.started":"2023-04-05T02:49:52.942744Z","shell.execute_reply":"2023-04-05T02:50:03.567273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xception.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:50:26.656369Z","iopub.execute_input":"2023-04-05T02:50:26.657290Z","iopub.status.idle":"2023-04-05T02:50:26.687781Z","shell.execute_reply.started":"2023-04-05T02:50:26.657257Z","shell.execute_reply":"2023-04-05T02:50:26.686510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    \n    model_xception.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='nadam',\n                  metrics=['sparse_categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:52:13.009566Z","iopub.execute_input":"2023-04-05T02:52:13.010828Z","iopub.status.idle":"2023-04-05T02:52:13.058853Z","shell.execute_reply.started":"2023-04-05T02:52:13.010771Z","shell.execute_reply":"2023-04-05T02:52:13.057579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------","metadata":{}},{"cell_type":"code","source":"# Learning Rate Schedule for Fine Tuning #\ndef exponential_lr(epoch,\n                   start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005,\n                   rampup_epochs = 5, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        # constant max_lr during sustain_epochs\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        # exponential decay towards min_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    \n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:52:19.711882Z","iopub.execute_input":"2023-04-05T02:52:19.712778Z","iopub.status.idle":"2023-04-05T02:52:19.957823Z","shell.execute_reply.started":"2023-04-05T02:52:19.712745Z","shell.execute_reply":"2023-04-05T02:52:19.956631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEPS_PER_EPOCH = 20\n\nhistory = model_xception.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback, tf.keras.callbacks.ModelCheckpoint(filepath='Xception.h5', monitor='val_loss',\n                                            save_best_only=True)],\n    workers=3\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:55:40.458156Z","iopub.execute_input":"2023-04-05T02:55:40.459091Z","iopub.status.idle":"2023-04-05T03:03:43.432753Z","shell.execute_reply.started":"2023-04-05T02:55:40.459053Z","shell.execute_reply":"2023-04-05T03:03:43.430881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ignore","metadata":{}},{"cell_type":"code","source":"# Learning Rate Schedule for Fine Tuning #\ndef exponential_lr(epoch,\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005,\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  rampup_epochs = 5, sustain_epochs = 0,\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  exp_decay = 0.8):\n\nÂ \n\nÂ Â Â  def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\nÂ Â Â Â Â Â Â  # linear increase from start to rampup_epochs\nÂ Â Â Â Â Â Â  if epoch < rampup_epochs:\nÂ Â Â Â Â Â Â Â Â Â Â  lr = ((max_lr - start_lr) /\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  rampup_epochs * epoch + start_lr)\nÂ Â Â Â Â Â Â  # constant max_lr during sustain_epochs\nÂ Â Â Â Â Â Â  elif epoch < rampup_epochs + sustain_epochs:\nÂ Â Â Â Â Â Â Â Â Â Â  lr = max_lr\nÂ Â Â Â Â Â Â  # exponential decay towards min_lr\nÂ Â Â Â Â Â Â  else:\nÂ Â Â Â Â Â Â Â Â Â Â  lr = ((max_lr - min_lr) *\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  min_lr)\nÂ Â Â Â Â Â Â  return lr\nÂ Â Â  return lr(epoch,\nÂ Â Â Â Â Â Â Â Â Â Â Â Â  start_lr,\nÂ Â Â Â Â Â Â Â Â Â Â Â Â  min_lr,\nÂ Â Â Â Â Â Â Â Â Â Â Â Â  max_lr,\nÂ Â Â Â Â Â Â Â Â Â Â Â Â  rampup_epochs,\nÂ Â Â Â Â Â Â Â Â Â Â Â Â  sustain_epochs,\nÂ Â Â Â Â Â Â Â Â Â Â Â Â  exp_decay)\n\nÂ \n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\nÂ \n\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:39:09.925312Z","iopub.execute_input":"2023-04-05T02:39:09.926163Z","iopub.status.idle":"2023-04-05T02:39:09.941744Z","shell.execute_reply.started":"2023-04-05T02:39:09.926126Z","shell.execute_reply":"2023-04-05T02:39:09.940014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ignore","metadata":{}},{"cell_type":"code","source":"EPOCHS = 20\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nÂ \n\nhistory = modelThreeNew.fit(\nÂ Â Â  ds_train,\nÂ Â Â  validation_data=ds_valid,\nÂ Â Â  epochs=EPOCHS,\nÂ Â Â  steps_per_epoch=STEPS_PER_EPOCH,\nÂ Â Â  callbacks=[lr_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:39:10.275885Z","iopub.execute_input":"2023-04-05T02:39:10.276868Z","iopub.status.idle":"2023-04-05T02:39:10.283642Z","shell.execute_reply.started":"2023-04-05T02:39:10.276826Z","shell.execute_reply":"2023-04-05T02:39:10.282124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:07:00.074050Z","iopub.execute_input":"2023-04-05T03:07:00.074562Z","iopub.status.idle":"2023-04-05T03:07:00.814263Z","shell.execute_reply.started":"2023-04-05T03:07:00.074526Z","shell.execute_reply":"2023-04-05T03:07:00.812873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilitiesThree = model_xception.predict(images_ds)\ncm_predictionsThree = np.argmax(cm_probabilitiesThree, axis=-1)\n\nlabels = range(len(CLASSES))\ncmatThree = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsThree,\n    labels=labels,\n)\ncmatThree = (cmatThree.T / cmatThree.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:07:16.038937Z","iopub.execute_input":"2023-04-05T03:07:16.040158Z","iopub.status.idle":"2023-04-05T03:07:43.119888Z","shell.execute_reply.started":"2023-04-05T03:07:16.040121Z","shell.execute_reply":"2023-04-05T03:07:43.118447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nscoreThree = f1_score(\n    cm_correct_labels,\n    cm_predictionsThree,\n    labels=labels,\n    average='macro',\n)\nprecisionThree = precision_score(\n    cm_correct_labels,\n    cm_predictionsThree,\n    labels=labels,\n    average='macro',\n)\nrecallThree = recall_score(\n    cm_correct_labels,\n    cm_predictionsThree,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmatThree, scoreThree, precisionThree, recallThree)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:40:35.936115Z","iopub.execute_input":"2023-04-05T03:40:35.937269Z","iopub.status.idle":"2023-04-05T03:40:38.080877Z","shell.execute_reply.started":"2023-04-05T03:40:35.937234Z","shell.execute_reply":"2023-04-05T03:40:38.079304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nconfusion = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsThree,\n    labels=labels,\n)\n\ntotal = np.sum(confusion)\naccuracy = np.trace(confusion) / float(total)\nspecificity = np.diag(confusion)[0] / np.sum(confusion[0])\nsensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\nppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\nnpv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n\n# Print the results\nprint(\"Model Five - Data Augmentation - Combination of Both\")\nprint(\"Accuracy:\", accuracy)\nprint(\"Specificity:\", specificity)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"PPV:\", ppv)\nprint(\"NPV:\", npv)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:40:57.046534Z","iopub.execute_input":"2023-04-05T03:40:57.047073Z","iopub.status.idle":"2023-04-05T03:40:57.059188Z","shell.execute_reply.started":"2023-04-05T03:40:57.047038Z","shell.execute_reply":"2023-04-05T03:40:57.057751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explaore Augmentation Dataset","metadata":{}},{"cell_type":"code","source":"def batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object: # binary string in this case,\n                                     # these are image ID strings\n        numpy_labels = [None for _ in enumerate(numpy_images)]\n    # If no labels, only image IDs, return None for labels (this is\n    # the case for test data)\n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image * 0.5 + 0.5)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n    \ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square\n    # or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:51:05.084560Z","iopub.execute_input":"2023-04-05T02:51:05.085268Z","iopub.status.idle":"2023-04-05T02:51:05.104342Z","shell.execute_reply.started":"2023-04-05T02:51:05.085237Z","shell.execute_reply":"2023-04-05T02:51:05.103169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_iter = iter(ds_train.unbatch().batch(20))","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:51:15.283366Z","iopub.execute_input":"2023-04-05T02:51:15.283789Z","iopub.status.idle":"2023-04-05T02:51:15.446055Z","shell.execute_reply.started":"2023-04-05T02:51:15.283757Z","shell.execute_reply":"2023-04-05T02:51:15.444665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"one_batch = next(ds_iter)\ndisplay_batch_of_images(one_batch)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T02:51:19.040889Z","iopub.execute_input":"2023-04-05T02:51:19.041783Z","iopub.status.idle":"2023-04-05T02:51:26.162514Z","shell.execute_reply.started":"2023-04-05T02:51:19.041746Z","shell.execute_reply":"2023-04-05T02:51:26.160923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation model 3","metadata":{}},{"cell_type":"code","source":"def get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment_method_two, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.map(random_cut_out, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:26:47.826797Z","iopub.execute_input":"2023-04-05T04:26:47.827723Z","iopub.status.idle":"2023-04-05T04:26:47.835504Z","shell.execute_reply.started":"2023-04-05T04:26:47.827684Z","shell.execute_reply":"2023-04-05T04:26:47.833803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()\n\nprint(\"Training:\", ds_train)\nprint (\"Validation:\", ds_valid)\nprint(\"Test:\", ds_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:26:51.103115Z","iopub.execute_input":"2023-04-05T04:26:51.104290Z","iopub.status.idle":"2023-04-05T04:26:51.464565Z","shell.execute_reply.started":"2023-04-05T04:26:51.104254Z","shell.execute_reply":"2023-04-05T04:26:51.463079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    pretrained_model_xception_two = tf.keras.applications.Xception(input_shape=[*IMAGE_SIZE, 3],\n                                               include_top=False,\n                                               weights='imagenet')\n    \n    model_xception_two = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model_xception_two,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:27:02.915580Z","iopub.execute_input":"2023-04-05T04:27:02.916387Z","iopub.status.idle":"2023-04-05T04:27:13.049168Z","shell.execute_reply.started":"2023-04-05T04:27:02.916352Z","shell.execute_reply":"2023-04-05T04:27:13.047889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xception_two.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:27:16.701030Z","iopub.execute_input":"2023-04-05T04:27:16.702165Z","iopub.status.idle":"2023-04-05T04:27:16.732492Z","shell.execute_reply.started":"2023-04-05T04:27:16.702128Z","shell.execute_reply":"2023-04-05T04:27:16.731186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    \n    model_xception_two.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='nadam',\n                  metrics=['sparse_categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:28:04.050414Z","iopub.execute_input":"2023-04-05T04:28:04.051619Z","iopub.status.idle":"2023-04-05T04:28:04.138681Z","shell.execute_reply.started":"2023-04-05T04:28:04.051584Z","shell.execute_reply":"2023-04-05T04:28:04.137293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning Rate Schedule for Fine Tuning #\ndef exponential_lr(epoch,\n                   start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005,\n                   rampup_epochs = 5, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        # constant max_lr during sustain_epochs\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        # exponential decay towards min_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    \n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:27:23.731332Z","iopub.execute_input":"2023-04-05T04:27:23.732241Z","iopub.status.idle":"2023-04-05T04:27:23.970252Z","shell.execute_reply.started":"2023-04-05T04:27:23.732207Z","shell.execute_reply":"2023-04-05T04:27:23.969116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 20 epoches","metadata":{}},{"cell_type":"code","source":"STEPS_PER_EPOCH = 20\n\nhistory = model_xception_two.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback, tf.keras.callbacks.ModelCheckpoint(filepath='Xception.h5', monitor='val_loss',\n                                            save_best_only=True)],\n    workers=3\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:23:59.262954Z","iopub.execute_input":"2023-04-05T03:23:59.263882Z","iopub.status.idle":"2023-04-05T03:33:16.264658Z","shell.execute_reply.started":"2023-04-05T03:23:59.263848Z","shell.execute_reply":"2023-04-05T03:33:16.262908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:35:55.546315Z","iopub.execute_input":"2023-04-05T03:35:55.546757Z","iopub.status.idle":"2023-04-05T03:35:56.205731Z","shell.execute_reply.started":"2023-04-05T03:35:55.546725Z","shell.execute_reply":"2023-04-05T03:35:56.204279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilitiesSix = model_xception_two.predict(images_ds)\ncm_predictionsSix = np.argmax(cm_probabilitiesSix, axis=-1)\n\nlabels = range(len(CLASSES))\ncmatSix = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsSix,\n    labels=labels,\n)\ncmatSix = (cmatSix.T / cmatSix.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:36:24.706669Z","iopub.execute_input":"2023-04-05T03:36:24.707535Z","iopub.status.idle":"2023-04-05T03:36:51.504163Z","shell.execute_reply.started":"2023-04-05T03:36:24.707496Z","shell.execute_reply":"2023-04-05T03:36:51.502605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nscoreSix = f1_score(\n    cm_correct_labels,\n    cm_predictionsSix,\n    labels=labels,\n    average='macro',\n)\nprecisionSix = precision_score(\n    cm_correct_labels,\n    cm_predictionsSix,\n    labels=labels,\n    average='macro',\n)\nrecallSix = recall_score(\n    cm_correct_labels,\n    cm_predictionsSix,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmatSix, scoreSix, precisionSix, recallSix)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:36:59.467513Z","iopub.execute_input":"2023-04-05T03:36:59.468635Z","iopub.status.idle":"2023-04-05T03:37:01.636851Z","shell.execute_reply.started":"2023-04-05T03:36:59.468598Z","shell.execute_reply":"2023-04-05T03:37:01.635387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nconfusion = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsSix,\n    labels=labels,\n)\n\ntotal = np.sum(confusion)\naccuracy = np.trace(confusion) / float(total)\nspecificity = np.diag(confusion)[0] / np.sum(confusion[0])\nsensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\nppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\nnpv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n\n# Print the results\nprint(\"Model Six - Data Augmentation - Flip Only\")\nprint(\"Accuracy:\", accuracy)\nprint(\"Specificity:\", specificity)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"PPV:\", ppv)\nprint(\"NPV:\", npv)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:38:05.960914Z","iopub.execute_input":"2023-04-05T03:38:05.961809Z","iopub.status.idle":"2023-04-05T03:38:05.974821Z","shell.execute_reply.started":"2023-04-05T03:38:05.961775Z","shell.execute_reply":"2023-04-05T03:38:05.973221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 35 epoches","metadata":{}},{"cell_type":"code","source":"STEPS_PER_EPOCH = 35\n\nhistory = model_xception_two.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback, tf.keras.callbacks.ModelCheckpoint(filepath='Xception.h5', monitor='val_loss',\n                                            save_best_only=True)],\n    workers=3\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:28:13.788213Z","iopub.execute_input":"2023-04-05T04:28:13.789287Z","iopub.status.idle":"2023-04-05T04:46:49.867510Z","shell.execute_reply.started":"2023-04-05T04:28:13.789244Z","shell.execute_reply":"2023-04-05T04:46:49.865886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:47:07.210007Z","iopub.execute_input":"2023-04-05T04:47:07.210961Z","iopub.status.idle":"2023-04-05T04:47:07.889084Z","shell.execute_reply.started":"2023-04-05T04:47:07.210926Z","shell.execute_reply":"2023-04-05T04:47:07.887446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilitiesSix35 = model_xception_two.predict(images_ds)\ncm_predictionsSix35 = np.argmax(cm_probabilitiesSix35, axis=-1)\n\nlabels = range(len(CLASSES))\ncmatSix = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsSix35,\n    labels=labels,\n)\ncmatSix = (cmatSix.T / cmatSix.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:47:17.291171Z","iopub.execute_input":"2023-04-05T04:47:17.291980Z","iopub.status.idle":"2023-04-05T04:47:44.445338Z","shell.execute_reply.started":"2023-04-05T04:47:17.291941Z","shell.execute_reply":"2023-04-05T04:47:44.443901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nscoreSix = f1_score(\n    cm_correct_labels,\n    cm_predictionsSix35,\n    labels=labels,\n    average='macro',\n)\nprecisionSix = precision_score(\n    cm_correct_labels,\n    cm_predictionsSix35,\n    labels=labels,\n    average='macro',\n)\nrecallSix = recall_score(\n    cm_correct_labels,\n    cm_predictionsSix35,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmatSix, scoreSix, precisionSix, recallSix)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:48:03.500694Z","iopub.execute_input":"2023-04-05T04:48:03.501081Z","iopub.status.idle":"2023-04-05T04:48:05.633216Z","shell.execute_reply.started":"2023-04-05T04:48:03.501052Z","shell.execute_reply":"2023-04-05T04:48:05.631980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nconfusion = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsSix35,\n    labels=labels,\n)\n\ntotal = np.sum(confusion)\naccuracy = np.trace(confusion) / float(total)\nspecificity = np.diag(confusion)[0] / np.sum(confusion[0])\nsensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\nppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\nnpv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n\n# Print the results\nprint(\"Model Six - Data Augmentation - Flip Only - 35 Epoches\")\nprint(\"Accuracy:\", accuracy)\nprint(\"Specificity:\", specificity)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"PPV:\", ppv)\nprint(\"NPV:\", npv)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:49:38.240209Z","iopub.execute_input":"2023-04-05T04:49:38.241052Z","iopub.status.idle":"2023-04-05T04:49:38.252999Z","shell.execute_reply.started":"2023-04-05T04:49:38.241015Z","shell.execute_reply":"2023-04-05T04:49:38.251565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# NEW","metadata":{}},{"cell_type":"markdown","source":"# Data Augmentation model 4","metadata":{}},{"cell_type":"code","source":"\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment_method_three, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.map(random_cut_out, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:43:47.024333Z","iopub.execute_input":"2023-04-05T03:43:47.025367Z","iopub.status.idle":"2023-04-05T03:43:47.032233Z","shell.execute_reply.started":"2023-04-05T03:43:47.025334Z","shell.execute_reply":"2023-04-05T03:43:47.030792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:42:19.669750Z","iopub.execute_input":"2023-04-05T03:42:19.670871Z","iopub.status.idle":"2023-04-05T03:42:20.177042Z","shell.execute_reply.started":"2023-04-05T03:42:19.670835Z","shell.execute_reply":"2023-04-05T03:42:20.175578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    pretrained_model_xception_three = tf.keras.applications.Xception(input_shape=[*IMAGE_SIZE, 3],\n                                               include_top=False,\n                                               weights='imagenet')\n    \n    model_xception_three = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model_xception_three,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:43:52.919433Z","iopub.execute_input":"2023-04-05T03:43:52.920330Z","iopub.status.idle":"2023-04-05T03:44:03.308223Z","shell.execute_reply.started":"2023-04-05T03:43:52.920296Z","shell.execute_reply":"2023-04-05T03:44:03.306532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xception_three.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:44:12.621007Z","iopub.execute_input":"2023-04-05T03:44:12.621836Z","iopub.status.idle":"2023-04-05T03:44:12.652530Z","shell.execute_reply.started":"2023-04-05T03:44:12.621804Z","shell.execute_reply":"2023-04-05T03:44:12.651102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    \n    model_xception_three.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='nadam',\n                  metrics=['sparse_categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:44:24.388128Z","iopub.execute_input":"2023-04-05T03:44:24.388782Z","iopub.status.idle":"2023-04-05T03:44:24.437683Z","shell.execute_reply.started":"2023-04-05T03:44:24.388747Z","shell.execute_reply":"2023-04-05T03:44:24.436259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning Rate Schedule for Fine Tuning #\ndef exponential_lr(epoch,\n                   start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005,\n                   rampup_epochs = 5, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        # constant max_lr during sustain_epochs\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        # exponential decay towards min_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    \n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:44:27.150383Z","iopub.execute_input":"2023-04-05T03:44:27.151064Z","iopub.status.idle":"2023-04-05T03:44:27.408372Z","shell.execute_reply.started":"2023-04-05T03:44:27.151033Z","shell.execute_reply":"2023-04-05T03:44:27.406966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEPS_PER_EPOCH = 20\n\nhistory = model_xception_three.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback, tf.keras.callbacks.ModelCheckpoint(filepath='Xception.h5', monitor='val_loss',\n                                            save_best_only=True)],\n    workers=3\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T03:44:37.766036Z","iopub.execute_input":"2023-04-05T03:44:37.766613Z","iopub.status.idle":"2023-04-05T03:54:03.126873Z","shell.execute_reply.started":"2023-04-05T03:44:37.766582Z","shell.execute_reply":"2023-04-05T03:54:03.125414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:01:01.632944Z","iopub.execute_input":"2023-04-05T04:01:01.633755Z","iopub.status.idle":"2023-04-05T04:01:02.297926Z","shell.execute_reply.started":"2023-04-05T04:01:01.633716Z","shell.execute_reply":"2023-04-05T04:01:02.296611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilitiesFour = model_xception_three.predict(images_ds)\ncm_predictionsFour = np.argmax(cm_probabilitiesFour, axis=-1)\n\nlabels = range(len(CLASSES))\ncmatFour = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsFour,\n    labels=labels,\n)\ncmatFour = (cmatFour.T / cmatFour.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:01:10.441471Z","iopub.execute_input":"2023-04-05T04:01:10.442259Z","iopub.status.idle":"2023-04-05T04:01:36.515474Z","shell.execute_reply.started":"2023-04-05T04:01:10.442220Z","shell.execute_reply":"2023-04-05T04:01:36.513831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nscoreFour = f1_score(\n    cm_correct_labels,\n    cm_predictionsFour,\n    labels=labels,\n    average='macro',\n)\nprecisionFour = precision_score(\n    cm_correct_labels,\n    cm_predictionsFour,\n    labels=labels,\n    average='macro',\n)\nrecallFour = recall_score(\n    cm_correct_labels,\n    cm_predictionsFour,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmatFour, scoreFour, precisionFour, recallFour)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:01:49.350355Z","iopub.execute_input":"2023-04-05T04:01:49.350994Z","iopub.status.idle":"2023-04-05T04:01:51.529375Z","shell.execute_reply.started":"2023-04-05T04:01:49.350945Z","shell.execute_reply":"2023-04-05T04:01:51.527969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nconfusion = confusion_matrix(\n    cm_correct_labels,\n    cm_predictionsFour,\n    labels=labels,\n)\n\ntotal = np.sum(confusion)\naccuracy = np.trace(confusion) / float(total)\nspecificity = np.diag(confusion)[0] / np.sum(confusion[0])\nsensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\nppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\nnpv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n\n# Print the results\nprint(\"Model Four - Data Augmentation - White Squares only\")\nprint(\"Accuracy:\", accuracy)\nprint(\"Specificity:\", specificity)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"PPV:\", ppv)\nprint(\"NPV:\", npv)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T04:02:01.683304Z","iopub.execute_input":"2023-04-05T04:02:01.684526Z","iopub.status.idle":"2023-04-05T04:02:01.696557Z","shell.execute_reply.started":"2023-04-05T04:02:01.684489Z","shell.execute_reply":"2023-04-05T04:02:01.695070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161321) to chat with other Learners.*","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}